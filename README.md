# ğŸ›¡ï¸ Redacted: Dynamic RAG Security Gateway

**A Full-Stack AI Security Platform utilizing RAG to validate LLM inputs against organizational policies.**
> Keep your AI conversations â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

![Project Status](https://img.shields.io/badge/Status-Active_Development-green)
![Stack](https://img.shields.io/badge/Stack-React_|_FastAPI_|_LangChain_|_AWS-blue)

---

## ğŸ¯ Project Overview

Redacted is a **Semantic Firewall** for Large Language Models. Unlike traditional security tools that rely on static keywords (Regex), Redacted uses **RAG (Retrieval Augmented Generation)** to dynamically fetch security policies and validate user prompts against them in real-time.

**The Problem:** Static filters cannot understand context or evolving company policies.
**The Solution:** A dynamic guardrail system that "reads" the company's rulebook before approving any request.

### âœ¨ Key Features
* **Interactive Playground (React):** A dual-pane dashboard to test prompts and visualize the security decision process.
* **Dynamic Rule Retrieval:** Uses a Vector DB (Pinecone/Chroma) to find relevant security policies for each specific prompt.
* **Transparent Decision Logic:** Shows exactly which "documents" caused a block (Explainable AI).
* **AWS Ready:** Designed to run on AWS Lambda (Backend) and S3/CloudFront (Frontend).

---

## ğŸ—ï¸ Architecture

### High-Level Flow
1. **Client (React):** User sends a prompt via the Dashboard.
2. **API (FastAPI):** Receives the request.
3. **Guardrail Chain (LangChain):**
   * **Step A:** Basic Regex Filter (SQL Injection, classic jailbreaks).
   * **Step B (RAG):** Queries the **Vector DB** for relevant policy documents based on the prompt.
   * **Step C (LLM Judge):** An LLM evaluates the prompt *given* the retrieved policies.
4. **Response:** The system returns either the safe answer OR a detailed rejection log to the frontend.

```mermaid
graph LR
    A[React Client] -->|Prompt| B(FastAPI Gateway)
    B --> C{Guardrail Chain}
    C -->|1. Check Cache| D[Redis]
    C -->|2. Retrieve Rules| E[Vector DB]
    C -->|3. Evaluate| F[LLM Judge]
    F -->|Safe| G[Target LLM]
    F -->|Unsafe| H[Block & Log]
    G --> A
    H --> A
```

---

## ğŸ› ï¸ Tech Stack

### Frontend (Client)
* **Framework:** React (Vite)
* **Styling:** Tailwind CSS (Dark Mode optimized)
* **State Management:** Zustand (Handling async analysis flows)
* **Visualization:** Framer Motion (for smooth transitions between checking steps)

### Backend (Server)
* **API:** FastAPI (Python)
* **Orchestration:** LangChain / LangGraph
* **Vector Database:** Pinecone (Production) / ChromaDB (Local dev)
* **LLM:** AWS Bedrock or OpenAI GPT-4o

### DevOps & Cloud
* **Compute:** AWS Lambda (Dockerized)
* **Deployment:** Docker + GitHub Actions

---

## ğŸš€ Getting Started

### Prerequisites
* Node.js v18+
* Python 3.10+
* Docker
* Pinecone API Key & OpenAI/AWS Key

### Installation

#### 1. Clone the repository
```bash
git clone <your-repo-url>
cd llm-security-gateway
```

#### 2. Setup Backend
```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Ingest the policy documents into Vector DB
python scripts/ingest.py

# Start the API server
uvicorn app.main:app --reload
```

#### 3. Access the Application
* **Redacted (UI):** http://localhost:3000 â€“ see [REDACTED.md](./REDACTED.md) to run
* **Backend API:** http://localhost:8000
* **API Docs:** http://localhost:8000/docs

### Redacted (Link management)

The project also includes **Redacted** â€“ a link management platform (shortening, analytics, custom links). The frontend lives in the `redacted/` folder.

For detailed setup and run instructions, see **[REDACTED.md](./REDACTED.md)**. Quick start:

```bash
cd redacted
npm install
# Configure .env (Clerk, MongoDB) â€“ see redacted/.env.example
npm run dev
```

â†’ **http://localhost:3000**

---

## ğŸ“‚ Project Structure

```
llm-security-gateway/
â”‚
â”œâ”€â”€ backend/                   # Python FastAPI Application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/               # API Routes (Endpoints)
â”‚   â”‚   â”‚   â”œâ”€â”€ endpoints/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ analyze.py # Main endpoint for prompt analysis
â”‚   â”‚   â”‚   â””â”€â”€ router.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ core/              # Config & Security
â”‚   â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ chains/            # LangChain Logic (The Brain)
â”‚   â”‚   â”‚   â”œâ”€â”€ guardrail.py   # The main RAG + Judge chain
â”‚   â”‚   â”‚   â””â”€â”€ prompts.py     # System prompts for the Judge LLM
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/          # External Integrations
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_db.py   # Pinecone/Chroma logic
â”‚   â”‚   â”‚   â””â”€â”€ llm_provider.py# Wrapper for OpenAI/AWS Bedrock
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ main.py            # App entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                  # Knowledge Base
â”‚   â”‚   â”œâ”€â”€ policies/          # PDF/TXT files (Company Rules)
â”‚   â”‚   â””â”€â”€ attacks/           # Examples of known attacks
â”‚   â”‚
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ ingest.py          # Script to load 'data/' into Vector DB
â”‚   â”‚
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile             # For AWS Lambda deployment
â”‚
â”œâ”€â”€ infra/                     # Infrastructure as Code (Optional/Future)
â”‚   â””â”€â”€ aws/                   # Terraform or CDK files
â”‚
â”œâ”€â”€ redacted/                  # Redacted â€“ Link management (Next.js)
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ prisma/
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ docker-compose.yml         # Run everything locally
â””â”€â”€ README.md
```

---

## ğŸ” How It Works

### 1. User Submits a Prompt
The user types a question or request in the React frontend chat interface.

### 2. Basic Pattern Matching (Fast Filter)
Before anything expensive, the system checks for obvious red flags:
* SQL injection attempts
* Classic jailbreak phrases ("ignore previous instructions")
* Known malicious patterns

**Speed:** < 10ms

### 3. RAG Policy Retrieval
If the prompt passes the basic filter, the system:
1. Converts the prompt into a vector embedding
2. Searches the Vector DB for the most relevant policy documents
3. Retrieves the top 3-5 matching policies

**Example:** If the prompt is "Can I share customer emails with vendors?", the system retrieves the "Data Privacy Policy" and "Third-Party Sharing Guidelines".

### 4. LLM Judge Evaluation
An LLM (GPT-4 or Claude) is given:
* The original user prompt
* The retrieved policy documents
* A system prompt that says: "Evaluate if this request violates any of these policies"

The LLM returns:
```json
{
  "is_safe": false,
  "reason": "This violates Section 4.2 of the Data Privacy Policy",
  "confidence": 0.92
}
```

### 5. Response to User
**If Safe:** The prompt is forwarded to the target LLM (ChatGPT, Claude, etc.) and the response is returned.
**If Unsafe:** The user sees a detailed explanation of why the request was blocked, including the specific policy section violated.

---

## ğŸ“Š Example Use Cases

### Use Case 1: HR Policy Compliance
**Scenario:** Company chatbot that answers employee questions.

**Policy Documents in Vector DB:**
* HR_Manual.pdf
* Remote_Work_Policy.pdf
* Time_Off_Guidelines.pdf

**User Prompt:** "Can I take 6 weeks of vacation in a row?"

**System Response:**
* **RAG Retrieval:** Finds section 3.4 of Time_Off_Guidelines.pdf
* **LLM Judge:** "Maximum consecutive vacation is 3 weeks (Section 3.4)"
* **Output:** "No, company policy limits consecutive vacation to 3 weeks. You can split it into multiple periods."

---

### Use Case 2: Customer Data Protection
**Scenario:** Sales team chatbot with access to customer data.

**Policy Documents:**
* GDPR_Compliance.pdf
* Data_Retention_Policy.pdf
* Customer_Data_Usage.pdf

**User Prompt:** "Send me a list of all customers who bought Product X in 2022"

**System Response:**
* **RAG Retrieval:** Finds sections on "Bulk Data Export" and "Purpose Limitation"
* **LLM Judge:** "Bulk customer data export requires manager approval (GDPR Compliance, Section 5)"
* **Output:** "This request requires manager approval. Please submit a data access request form."

---

## ğŸ¨ Frontend Features

### Split-Screen Dashboard
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chat Interface  â”‚  Under the Hood          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  â”‚  Step 1: Pattern Check âœ“ â”‚
â”‚  User: "Can I    â”‚  - No SQL detected       â”‚
â”‚  share customer  â”‚  - No jailbreak patterns â”‚
â”‚  emails?"        â”‚                          â”‚
â”‚                  â”‚  Step 2: RAG Retrieval â³â”‚
â”‚                  â”‚  - Searching policies... â”‚
â”‚                  â”‚  - Found 3 matches       â”‚
â”‚                  â”‚                          â”‚
â”‚                  â”‚  Step 3: LLM Judge â³    â”‚
â”‚                  â”‚  - Evaluating...         â”‚
â”‚                  â”‚                          â”‚
â”‚  System: "This   â”‚  âŒ BLOCKED              â”‚
â”‚  violates..."    â”‚  Reason: Data Privacy... â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Security Benefits

### Traditional Approach (Static Rules)
```python
# Old way: Brittle and easy to bypass
if "password" in prompt.lower():
    return "BLOCKED"
```
**Problem:** Doesn't understand context. Blocks legitimate questions like "How do I reset my password?"

### Redacted Approach (Dynamic RAG)
```python
# New way: Context-aware
retrieved_policies = vector_db.search(prompt)
decision = llm_judge.evaluate(prompt, retrieved_policies)
```
**Advantage:** Understands intent and context. Allows "How do I reset my password?" but blocks "What is John's password?"

---

## ğŸš¢ Deployment

### Local Development (Docker Compose)
```bash
docker-compose up
```

### AWS Lambda (Production)
1. Build Docker image:
```bash
cd backend
(python3 -m uvicorn main:app --reload)
or
docker build -t redacted-api .
```

2. Push to ECR and deploy with AWS Lambda

3. Redacted (Next.js): Deploy to Vercel, or build and serve with `npm run build && npm start` behind your host.

---

## ğŸ“ˆ Performance Targets

| Metric                  | Target     | Status |
|-------------------------|------------|--------|
| Average Response Time   | < 800ms    | ğŸ”„ TBD |
| RAG Retrieval Time      | < 200ms    | ğŸ”„ TBD |
| Cache Hit Rate          | > 70%      | ğŸ”„ TBD |
| False Positive Rate     | < 5%       | ğŸ”„ TBD |

---

## ğŸ“„ License

MIT License

---

## ğŸ‘¤ Author

**Lidor Pahima**
* AI Engineer
* Email: lidorpahima28@gmail.com
* LinkedIn: [linkedin.com/in/lidor-pahima](https://linkedin.com/in/lidor-pahima)
* GitHub: [github.com/Lidorpahima](https://github.com/Lidorpahima)

---

## ğŸ™ Acknowledgments

* Built with modern AI security best practices
* Inspired by real-world LLM security challenges
* Designed for production deployment from day one

---

**â­ If you find this project interesting, please star it on GitHub!**
